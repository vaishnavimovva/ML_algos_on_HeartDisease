{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "812afed8",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks:\n",
    "* Artificial Neural Networks (ANN) are a subset of machine learning algorithms inspired by the structure and function of the human brain.\n",
    "* ANN algorithms are known for their ability to learn complex patterns and relationships in data. \n",
    "* ANNs consist of interconnected nodes, or neurons, that process and transmit information. These neurons are organized into layers, with input and output layers and one or more hidden layers in between.\n",
    "* During training, the weights of the connections between neurons are adjusted to minimize the error between the predicted output and the actual output. Once trained, the ANN can be used to make predictions on new data.\n",
    "* They are particularly useful for tasks that involve large amounts of data and require high accuracy. \n",
    "* However, they can be computationally expensive and require large amounts of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230bdc9f",
   "metadata": {},
   "source": [
    "The typical Artificial Neural Network looks something like the given figure.\n",
    "<img src=\"ANN.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea7a5a7",
   "metadata": {},
   "source": [
    "# Steps to Implement an ANN Algorithm:\n",
    "* Define the problem and gather data: The first step in implementing an ANN algorithm is to define the problem you want to solve and gather data that is relevant to that problem. For example, if you want to build an image classification system, you need to gather a dataset of labeled images.\n",
    "* Preprocess the data: Once you have gathered the data, you need to preprocess it to prepare it for use in the ANN algorithm. This may involve tasks such as normalization, scaling, and feature extraction.\n",
    "* Design the network architecture: The next step is to design the architecture of the ANN. This involves deciding on the number of layers, the number of neurons in each layer, and the activation functions to be used.\n",
    "* Train the network: Once the architecture has been designed, the next step is to train the network using the preprocessed data. This involves adjusting the weights and biases of the network to minimize the error between the predicted outputs and the actual outputs.\n",
    "* Evaluate the network: After the network has been trained, it is important to evaluate its performance on a separate test dataset. This will give you an idea of how well the network is able to generalize to new data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47a86bf",
   "metadata": {},
   "source": [
    "The architecture of an artificial neural network looks like the given figure.\n",
    "<img src=\"ANN1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bc42bc",
   "metadata": {},
   "source": [
    "# Advantages of Artificial Neural Networks:\n",
    "* Parallel processing capability:Artificial neural networks have a numerical value that can perform more than one task simultaneously.\n",
    "* Storing data on the entire network:Data that is used in traditional programming is stored on the whole network, not on a database. The disappearance of a couple of pieces of data in one place doesn't prevent the network from working.\n",
    "* Capability to work with incomplete knowledge:After ANN training, the information may produce output even with inadequate data. The loss of performance here relies upon the significance of missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecffab76",
   "metadata": {},
   "source": [
    "# Dis-Advantages of Artificial Neural Networks:\n",
    "* Assurance of proper network structure:There is no particular guideline for determining the structure of artificial neural networks. The appropriate network structure is accomplished through experience, trial, and error.\n",
    "* Hardware dependence:Artificial neural networks need processors with parallel processing power, as per their structure. Therefore, the realization of the equipment is dependent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea8bd903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('New heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a69d48f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values (Replace 'M' with NaN)\n",
    "data = data.replace('M', np.nan)\n",
    "\n",
    "# Drop rows with missing target values (assuming 'target' is the column name)\n",
    "data.dropna(subset=['HeartDisease'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca6bd943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = data.drop('HeartDisease', axis=1)\n",
    "y = data['HeartDisease']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa1a3919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert non-numeric columns to numeric using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "X['Sex'] = label_encoder.fit_transform(X['Sex'])\n",
    "X['ChestPainType'] = label_encoder.fit_transform(X['ChestPainType'])\n",
    "X['RestingECG'] = label_encoder.fit_transform(X['RestingECG'])\n",
    "X['ExerciseAngina'] = label_encoder.fit_transform(X['ExerciseAngina'])\n",
    "X['ST_Slope'] = label_encoder.fit_transform(X['ST_Slope'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7795e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values in the feature columns\n",
    "X = X.fillna(X.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aef275f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62e44ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63bac202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the ANN model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2e2d3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "090e0be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "42/42 [==============================] - 1s 6ms/step - loss: 0.5853 - accuracy: 0.7591 - val_loss: 0.5479 - val_accuracy: 0.7297\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8652 - val_loss: 0.4747 - val_accuracy: 0.7838\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.3472 - accuracy: 0.8682 - val_loss: 0.4662 - val_accuracy: 0.7973\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.3290 - accuracy: 0.8697 - val_loss: 0.4598 - val_accuracy: 0.7838\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.3201 - accuracy: 0.8712 - val_loss: 0.4536 - val_accuracy: 0.7973\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3109 - accuracy: 0.8727 - val_loss: 0.4522 - val_accuracy: 0.7973\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3020 - accuracy: 0.8712 - val_loss: 0.4449 - val_accuracy: 0.7838\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2955 - accuracy: 0.8758 - val_loss: 0.4531 - val_accuracy: 0.7973\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2886 - accuracy: 0.8773 - val_loss: 0.4440 - val_accuracy: 0.7973\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2821 - accuracy: 0.8773 - val_loss: 0.4467 - val_accuracy: 0.7973\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2753 - accuracy: 0.8909 - val_loss: 0.4323 - val_accuracy: 0.8108\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2685 - accuracy: 0.8848 - val_loss: 0.4502 - val_accuracy: 0.7973\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2610 - accuracy: 0.8879 - val_loss: 0.4545 - val_accuracy: 0.7973\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2551 - accuracy: 0.8879 - val_loss: 0.4716 - val_accuracy: 0.7973\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2488 - accuracy: 0.8955 - val_loss: 0.4799 - val_accuracy: 0.7973\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2448 - accuracy: 0.8970 - val_loss: 0.4707 - val_accuracy: 0.8108\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2412 - accuracy: 0.9106 - val_loss: 0.4789 - val_accuracy: 0.8108\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2324 - accuracy: 0.9076 - val_loss: 0.4843 - val_accuracy: 0.8108\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2268 - accuracy: 0.9136 - val_loss: 0.4902 - val_accuracy: 0.8108\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2227 - accuracy: 0.9106 - val_loss: 0.4999 - val_accuracy: 0.8108\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2179 - accuracy: 0.9121 - val_loss: 0.4955 - val_accuracy: 0.8108\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2119 - accuracy: 0.9182 - val_loss: 0.5230 - val_accuracy: 0.8108\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2056 - accuracy: 0.9227 - val_loss: 0.5114 - val_accuracy: 0.7973\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2032 - accuracy: 0.9227 - val_loss: 0.5545 - val_accuracy: 0.8108\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1986 - accuracy: 0.9197 - val_loss: 0.5469 - val_accuracy: 0.8108\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1931 - accuracy: 0.9333 - val_loss: 0.5586 - val_accuracy: 0.7973\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1887 - accuracy: 0.9333 - val_loss: 0.5721 - val_accuracy: 0.7838\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1850 - accuracy: 0.9318 - val_loss: 0.5635 - val_accuracy: 0.7838\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1806 - accuracy: 0.9318 - val_loss: 0.5903 - val_accuracy: 0.7973\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1785 - accuracy: 0.9424 - val_loss: 0.6016 - val_accuracy: 0.7838\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1720 - accuracy: 0.9379 - val_loss: 0.5846 - val_accuracy: 0.7838\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1687 - accuracy: 0.9379 - val_loss: 0.6229 - val_accuracy: 0.7838\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1662 - accuracy: 0.9379 - val_loss: 0.6548 - val_accuracy: 0.7973\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1623 - accuracy: 0.9394 - val_loss: 0.6381 - val_accuracy: 0.7703\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1586 - accuracy: 0.9439 - val_loss: 0.6331 - val_accuracy: 0.7838\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1536 - accuracy: 0.9439 - val_loss: 0.6398 - val_accuracy: 0.7838\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1501 - accuracy: 0.9439 - val_loss: 0.6651 - val_accuracy: 0.7568\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1446 - accuracy: 0.9515 - val_loss: 0.6797 - val_accuracy: 0.7838\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1430 - accuracy: 0.9485 - val_loss: 0.6757 - val_accuracy: 0.7703\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1379 - accuracy: 0.9485 - val_loss: 0.7204 - val_accuracy: 0.7703\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1362 - accuracy: 0.9576 - val_loss: 0.7369 - val_accuracy: 0.7703\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1314 - accuracy: 0.9500 - val_loss: 0.7193 - val_accuracy: 0.7838\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1281 - accuracy: 0.9530 - val_loss: 0.7150 - val_accuracy: 0.7432\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1240 - accuracy: 0.9621 - val_loss: 0.7368 - val_accuracy: 0.7703\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1233 - accuracy: 0.9591 - val_loss: 0.7355 - val_accuracy: 0.7703\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1204 - accuracy: 0.9606 - val_loss: 0.7726 - val_accuracy: 0.7568\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1154 - accuracy: 0.9636 - val_loss: 0.8238 - val_accuracy: 0.7703\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9591 - val_loss: 0.7836 - val_accuracy: 0.7432\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1116 - accuracy: 0.9636 - val_loss: 0.7849 - val_accuracy: 0.7568\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1087 - accuracy: 0.9652 - val_loss: 0.8233 - val_accuracy: 0.7568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x24c5657f100>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ae2562d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56c530d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 93.81443298969072\n",
      "Recall: 85.04672897196261\n",
      "Accuracy: 88.04347826086956\n",
      "F1 Score: 89.2156862745098\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Precision:\", precision*100)\n",
    "print(\"Recall:\", recall*100)\n",
    "print(\"Accuracy:\", accuracy*100)\n",
    "print(\"F1 Score:\", f1*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951f69c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
